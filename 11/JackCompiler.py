#!/usr/bin/python

# File name: JackCompiler.py
# Description:
# The full scale Jack compiler
#
# Input: .jack file(s)
# Output: .xml file(s)


import sys
import os
import re

import xml.etree.ElementTree as ET
import xml.dom.minidom as md

class Tree:
    '''
    Used in expression evaluation
    '''
    class Node:
        def __init__(self, value):
            self.value = value
            self.leftChild = None
            self.rightChild = None

        def GetVal(self):
            return self.value

        def SetVal(self, value):
            self.value = value

        def GetLeft(self):
            return self.leftChild

        def GetRight(self):
            return self.rightChild

        def SetLeft(self, node):
            self.leftChild = node

        def SetRight(self, node):
            self.rightChild = node

    def __init__(self):
        self.root = None
        self.RPN = []

    def PostOrderTraversal(self, node):
        if None == node:
            return False
        self.PostOrderTraversal(node.leftChild)
        self.PostOrderTraversal(node.rightChild)
        self.RPN.append(node.GetVal())

    def AddNode(self, newNode):
        self.root = self.InsertNode(self.root, newNode)

    def AddVal(self, value):
        self.root = self.InsertVal(self.root, value)

    def InsertVal(self, node, value):
        if None == node:
            node = self.Node(value)
            return node

        if None == node.GetLeft():
            newNode = self.Node(value)
            # do the swap
            if value in "+-*/":
                tempVal = node.GetVal()
                node.SetVal(value)
                newNode.SetVal(tempVal)
            node.SetLeft(newNode)
            return node

        if None == node.GetRight():
            newNode = self.Node(value)
            # do the swap
            if value in "+-*/":
                tempVal = node.GetVal()
                node.SetVal(value)
                newNode.SetVal(tempVal)
            node.SetRight(newNode)
            return node

        leftNode = self.InsertVal(node.GetLeft(), value)
        nde.SetLeft(leftNode)
        return node

    def InsertNode(self, curNode, newNode):
        if None == curNode:
            curNode = newNode
            return curNode

        if None == curNode.GetLeft():
            curNode.SetLeft(newNode)
            return curNode

        if None == curNode.GetRight():
            curNode.SetRight(newNode)
            return curNode

        leftNode = self.InsertNode(curNode.GetLeft(), newNode)
        curNode.SetLeft(leftNode)
        return curNode


class Token:
    '''
    one single token
    '''
    def __init__(self, token_type, raw_str, match_str):
        self.token_type = token_type
        self.raw_str = raw_str
        self.match_str = match_str

    def get_type(self):
        return self.token_type

    def get_raw_str(self):
        return self.raw_str

    def get_mth_str(self):
        return self.match_str


class Regex:
    '''
    specific regex expression object with a name
    '''
    def __init__(self, reg_name, pattern):
        self.reg_name = reg_name
        self.reg_obj  = re.compile(pattern)

    def get_name(self):
        return self.reg_name

    def match(self, string):
        return self.reg_obj.match(string)


lex_ele_regex_list = [
    # lexical elements, please note the order of items in this list is important.
    Regex("keyword", "^(class|constructor|function|method|field|static|var|int|char|boolean|void|true|false|null|this|let|do|if|else|while|return)[\W]+"),
    Regex("symbol", "^(>=|<=|[{}()\[\]\.,;\+\-\*\/\&\|<>=~])"),
    Regex("integerConstant", "^(\d+)"),
    Regex("stringConstant", "^\"(.*?)\""),
    Regex("identifier", "^([a-zA-Z|\d]\w*)")
]

class CompilationEngine:
    '''
    Gets input from a JackTokenizer and emits parsed structure into an output file / stream.
    The output is generated by a series of compilexxx() routines, one for every syntactic element
    xxx of the Jack grammar.
    '''
    def __init__(self, jt):
        self.tokenizer = jt
        self.root = None    # the root element of the parse tree
        self.st = SymbolTable()
        self.vw = VMWriter(self.tokenizer.in_file_path)
        self.parameterNum = 0  # number of parameters in a subroutine
        self.varNum = 0  # number of local variables in a subroutine
        self.argNum = 0  # number of arguments supplied when a subroutine is called

    def StartCompiling(self):
        # the first program structure in a file is always class
        # and this function will recursively call other compile functions
        self.CompileClass()
        self.vw.CreateOutputFile()

    def CompileClass(self):
        '''
        Compile a complete class
        '''
        if None == self.tokenizer.current_token:
            self.tokenizer.advance()

        if "class" == self.tokenizer.keyWord():
            self.root = ET.Element("class")
            item = ET.SubElement(self.root, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        else:
            print "Failed to compile class"
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # className
        if self.tokenizer.identifier():
            item = ET.SubElement(self.root, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier(), )
            self.st.classNameList.append(self.tokenizer.identifier())
        else:
            print "Failed to match the identifier in %s" % (sys._getframe().f_code.co_name, )

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # symbol '{'
        if '{' == self.tokenizer.symbol():
            item = ET.SubElement(self.root, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
            return False

        # classVarDec*
        while self.CompileClassVarDec(self.root):
            pass

        # subroutineDec*
        while self.CompileSubroutineDec(self.root):
            pass

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # symbol '}'
        if '}' == self.tokenizer.symbol():
            item = ET.SubElement(self.root, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the '}' in %s, we got a %s" % (sys._getframe().f_code.co_name, self.tokenizer.keyWord(), )
            return False

        return True

    def CompileClassVarDec(self, parent):
        '''
        Compile a static declaration or a field declaration

        Arg:
            parent: the parent node which the tree nodes created in this function are attached to
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # (static | field)
        if "static" == self.tokenizer.keyWord() or "field" == self.tokenizer.keyWord():
            # since we know this is a classVarDec program structure
            parent = ET.SubElement(parent, "classVarDec")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
            classVarKind = self.tokenizer.keyWord()
        else:
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # type
        if "int" == self.tokenizer.keyWord() or \
           "char" == self.tokenizer.keyWord() or \
           "boolean" == self.tokenizer.keyWord():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
            classVarType = self.tokenizer.keyWord()
        elif self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier())
            classVarType = self.tokenizer.identifier()
        else:
            print "Failed to match the 'type' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # varName
        if self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier(), )
            classVarName = self.tokenizer.identifier()
        else:
            print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
            return False

        # add a class variable to the symbol table
        self.st.Define(classVarName, classVarType, classVarKind)

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # (, varName)*
        while "," == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            if self.tokenizer.identifier():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier(), )
                classVarName = self.tokenizer.identifier()
            else:
                print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
                return False

            self.st.Define(classVarName, classVarType, classVarKind)

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

        if ";" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
            return True
        else:
            print "Failed to match the ';' in %s" % (sys._getframe().f_code.co_name, )
            return False

    def CompileSubroutineDec(self, parent):
        '''
        Compile a complete method, function or constructor
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # (constructor | function | method)
        if "constructor" == self.tokenizer.keyWord() or \
           "function" == self.tokenizer.keyWord() or \
           "method" == self.tokenizer.keyWord():
            # since we know this is a subroutineDec program structure
            parent = ET.SubElement(parent, "subroutineDec")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        else:
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # void or type
        if "void" == self.tokenizer.keyWord():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        elif "int" == self.tokenizer.keyWord() or \
           "char" == self.tokenizer.keyWord() or \
           "boolean" == self.tokenizer.keyWord():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        elif self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier())
        else:
            print "Failed to match the '(void | type)' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # subroutineName
        if self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier())
            self.st.subroutineNameList.append(self.tokenizer.identifier())
            subroutineName = self.tokenizer.identifier()
        else:
            print "Failed to match the 'subroutineName' in %s" % (sys._getframe().f_code.co_name, )
            return False

        self.st.StartSubroutineScope(subroutineName)

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "(" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol())
        else:
            print "Failed to match the '(' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if False == self.CompileParameterList(parent):
            print "Failed to match the parameterList in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if ")" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol())
        else:
            print "Failedf to match the ')' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if False == self.CompileSubroutineBody(parent):
            print "Failed to match the subroutineBody in %s" % (sys._getframe().f_code.co_name, )
            return False

        self.st.EndSubroutineScope()

        return True

    def CompileParameterList(self, parent):
        '''
        Compile a (possibly empty) parameter list, not including the enclosing"()".
        '''
        self.parameterNum = 0
        parent = ET.SubElement(parent, "parameterList")
        ET.SubElement(parent, "pad")
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # type
        if "int" == self.tokenizer.keyWord() or \
           "char" == self.tokenizer.keyWord() or \
           "boolean" == self.tokenizer.keyWord():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
            argVarType = self.tokenizer.keyWord()
        elif self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier())
            argVarType = self.tokenizer.identifier()
        else:
            # the whole parameterList structure is optional
            self.tokenizer.rollBack()
            return True

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # varName
        if self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier(), )
            argVarName = self.tokenizer.identifier()
        else:
            print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
            return False

        self.st.Define(argVarName, argVarType, "argument")
        self.parameterNum += 1
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # (, type varName)*
        while "," == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            # type
            if "int" == self.tokenizer.keyWord() or \
               "char" == self.tokenizer.keyWord() or \
               "boolean" == self.tokenizer.keyWord():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.keyWord(), )
                argVarType = self.tokenizer.keyWord()
            elif self.tokenizer.identifier():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier())
                argVarType = self.tokenizer.identifier()
            else:
                print "Failed to match 'type' in %s" % (sys._getframe().f_code.co_name, )
                return False

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            # varName
            if self.tokenizer.identifier():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier(), )
                argVarName = self.tokenizer.identifier()
            else:
                print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
                return False

            self.st.Define(argVarName, argVarType, "argument")
            self.parameterNum += 1
            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

        self.tokenizer.rollBack()
        return True

    def CompileSubroutineBody(self, parent):
        '''
        Compile the body of a subroutine in a class
        '''
        parent = ET.SubElement(parent, "subroutineBody")
        ET.SubElement(parent, "pad")
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # '{'
        if "{" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
            return False

        while self.CompileVarDec(parent):
            pass

        self.vw.WriteFunction(self.st.classNameList[0] + "." + self.st.subroutineName, self.varNum)

        while self.CompileStatements(parent):
            pass

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # '}'
        if "}" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the '}' in %s" % (sys._getframe().f_code.co_name, )
            return False

        return True

    def CompileVarDec(self, parent):
        '''
        Compile a var declaration
        '''
        self.varNum = 0
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # 'var'
        if "var" == self.tokenizer.keyWord():
            # since we know this is a varDec program structure
            parent = ET.SubElement(parent, "varDec")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        else:
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # type
        if "int" == self.tokenizer.keyWord() or \
           "char" == self.tokenizer.keyWord() or \
           "boolean" == self.tokenizer.keyWord():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
            varType = self.tokenizer.keyWord()
        elif self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier())
            varType = self.tokenizer.identifier()
        else:
            print "Failed to match the 'type' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # varName
        if self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier(), )
            varName = self.tokenizer.identifier()
        else:
            print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
            return False

        self.st.Define(varName, varType, "var")
        self.varNum += 1

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # (, varName)*
        while "," == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            # varName
            if self.tokenizer.identifier():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier(), )
                varName = self.tokenizer.identifier()
            else:
                print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
                return False

            self.st.Define(varName, varType, "var")
            self.varNum += 1
            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

        if ";" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the ';' in %s" % (sys._getframe().f_code.co_name, )
            return False

        return True

    def CompileStatements(self, parent):
        '''
        Compile a sequence of statements, not inclduing the enclosing "{}".
        '''
        parent = ET.SubElement(parent, "statements")
        ET.SubElement(parent, "pad")
        while self.CompileDo(parent) or \
              self.CompileLet(parent) or \
              self.CompileWhile(parent) or \
              self.CompileReturn(parent) or \
              self.CompileIf(parent):
            pass
        return False

    def CompileDo(self, parent):
        '''
        Compile a do statement
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # 'do'
        if "do" == self.tokenizer.keyWord():
            # since we know this is a doStatement program structure
            parent = ET.SubElement(parent, "doStatement")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        else:
            self.tokenizer.rollBack()
            return False

        # subroutineCall
        if False == self.CompileSubroutineCall(parent):
            print "Failed to match the 'subroutineCall' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if ";" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the ';' in %s" % (sys._getframe().f_code.co_name, )
            return False

        return True

    def CompileSubroutineCall(self, parent):
        '''
        Note that subroutineCall is not a non-terminal structure
        '''
        # TODO: I assume all subroutines are functions for simplicity
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        name1 = ""
        name2 = ""
        # (subroutineName | className | varName)
        if self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier(), )
            name1 = self.tokenizer.identifier()
            # # look up this identifier in the symbol table
            # varName = self.tokenizer.identifier()
            # entry = self.st.FindSymbol(varName)

            # if None != entry:
            #     print "identifier %s found in symbol table, running index %d" % (varName, entry.GetIndex())
            # # check if this identifier is a class name
            # if varName in self.st.classNameList:
            #     print "identifier %s is a class name defined in the current file"
        else:
            print "Failed to match the 'subroutineName' in %s" % (sys._getframe().f_code.co_name, )
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "." == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )


            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            # subroutineName
            if self.tokenizer.identifier():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier(), )
                name2  = self.tokenizer.identifier()
            else:
                print "Failed to match 'subroutineName' in %s" % (sys._getframe().f_code.co_name, )
                return False

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

        if "(" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '(' in %s" % (sys._getframe().f_code.co_name, )
            return False

        self.CompileExpressionList(parent)

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if ")" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the ')' in %s" % (sys._getframe().f_code.co_name, )
            return False

        self.vw.WriteCall(name1 + "." + name2 if "" != name2 else name1, self.argNum)
        return True

    def CompileLet(self, parent):
        '''
        Compile a let statement
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # 'let'
        if "let" == self.tokenizer.keyWord():
            # since we know this is a letStatement program structure
            parent = ET.SubElement(parent, "letStatement")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )

        else:
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # varName
        if self.tokenizer.identifier():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.identifier(), )

            # look up this identifier in the symbol table
            varName = self.tokenizer.identifier()
            entry = self.st.FindSymbol(varName)

            if None == entry:
                print "Error: identifier %s referenced but not defined." % (varName, )
                return False
            else:
                print "identifier %s found in symbol table, running index %d" % (varName, entry.GetIndex())
        else:
            print "Failed to match the 'varName' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # ([expression])?
        if "[" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            if False == self.CompileExpression(parent):
                print "Failed to match the [expression] in %s" % (sys._getframe().f_code.co_name, )
                return False

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            if "]" == self.tokenizer.symbol():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.symbol(), )
            else:
                print "Failed to match the ']' in %s" % (sys._getframe().f_code.co_name, )
                return False

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

        if "=" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '=' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if False == self.CompileExpression(parent):
            print "Failed to match the expression in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if ";" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the ';' in %s" % (sys._getframe().f_code.co_name, )
            return False

        return True

    def CompileWhile(self, parent):
        '''
        Compile a while statement
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # 'while'
        if "while" == self.tokenizer.keyWord():
            # since we know this is a whileStatement program structure
            parent = ET.SubElement(parent, "whileStatement")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )

        else:
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "(" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the '(' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if False == self.CompileExpression(parent):
            print "Failed to match the expression in %s" % (sys._getframe().f_code.co_name, )

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if ")" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the ')' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "{" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
            return False

        while self.CompileStatements(parent):
            pass

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "}" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
            return False

        return True

    def CompileReturn(self, parent):
        '''
        Compile a return statement
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # 'return'
        if "return" == self.tokenizer.keyWord():
            # since we know this is a returnStatement program structure
            parent = ET.SubElement(parent, "returnStatement")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        else:
            self.tokenizer.rollBack()
            return False

        hasRetExp, parseTree = self.CompileExpression(parent)
        if False == hasRetExp:
            self.vw.WriteReturn(True)
        else:
            self.vm.WriteReturn(False)

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False
        if ";" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

        else:
            print "Failed to match the ';' in %s" % (sys._getframe().f_code.co_name, )
            return False

        return True

    def CompileIf(self, parent):
        '''
        Compilea if statement, possibly witha trailing else clause
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # 'if'
        if "if" == self.tokenizer.keyWord():
            # since we know this is a ifStatement program structure
            parent = ET.SubElement(parent, "ifStatement")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        else:
            self.tokenizer.rollBack()
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "(" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '(' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if False == self.CompileExpression(parent):
            print "Failed to match the expression in %s" % (sys._getframe().f_code.co_name, )

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if ")" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the ')' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "{" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
            return False

        while self.CompileStatements(parent):
            pass

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "}" == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
        else:
            print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
            return False

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        if "else" == self.tokenizer.keyWord():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )


            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            if "{" == self.tokenizer.symbol():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.symbol(), )
            else:
                print "Failed to match the '{' in %s" % (sys._getframe().f_code.co_name, )
                return False

            while self.CompileStatements(parent):
                pass

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

            if "}" == self.tokenizer.symbol():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.symbol(), )
            else:
                print "Failed to match the '}' in %s" % (sys._getframe().f_code.co_name, )
                return False
        else:
            self.tokenizer.rollBack()

        return True

    def CompileExpression(self, parent):
        '''
        Compile an expression
        '''
        subTree = Tree()
        # take a peek if the next token is a term
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False, subTree

        if self.tokenizer.identifier() or \
           "integerConstant" == self.tokenizer.tokenType() or \
           "stringConstant" == self.tokenizer.tokenType() or \
           "-" == self.tokenizer.symbol() or "~" == self.tokenizer.symbol() or \
           "(" == self.tokenizer.symbol() or \
           "true" == self.tokenizer.keyWord() or \
           "false" == self.tokenizer.keyWord() or \
           "null" == self.tokenizer.keyWord() or \
           "this" == self.tokenizer.keyWord():
            parent = ET.SubElement(parent, "expression")

        self.tokenizer.rollBack()

        retVal, subTree = self.CompileTerm(parent, subTree)
        if False == retVal:
            return False, subTree

        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False, subTree

        while ('+' == self.tokenizer.symbol() or \
               '-' == self.tokenizer.symbol() or \
               '*' == self.tokenizer.symbol() or \
               '/' == self.tokenizer.symbol() or \
               '&' == self.tokenizer.symbol() or \
               '|' == self.tokenizer.symbol() or \
               '<' == self.tokenizer.symbol() or \
               '>' == self.tokenizer.symbol() or \
               '=' == self.tokenizer.symbol()):
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            subTree.AddVal(self.tokenizer.symbol())

            retVal, subTree = self.CompileTerm(parent, subTree)
            if False == retVal:
                print "Failed to match 'term' in %s" % (sys._getframe().f_code.co_name, )
                return False, subTree

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False, subTree

        self.tokenizer.rollBack()
        return True, subTree

    def CompileTerm(self, parent, parseTree):
        '''
        Compile a term. This routine is faced with a slight diffculty when trying
        to decide between some of the alternative parsing rules.
        '''
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False, parseTree

        if "integerConstant" == self.tokenizer.tokenType():  # integerConstant
            parent = ET.SubElement(parent, "term")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %d " % (self.tokenizer.intVal(), )
            parseTree.AddVal(str(self.tokenizer.intVal()))

        elif "stringConstant" == self.tokenizer.tokenType():  # stringConstant
            parent = ET.SubElement(parent, "term")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.stringVal(), )
        elif "true" == self.tokenizer.keyWord() or \
             "false" == self.tokenizer.keyWord() or \
             "null" == self.tokenizer.keyWord() or \
             "this" == self.tokenizer.keyWord():  # keyWord constant
            parent = ET.SubElement(parent, "term")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.keyWord(), )
        elif self.tokenizer.identifier():  # a variable name or an array element or a subroutineCall
            parent = ET.SubElement(parent, "term")
            # check if it is subroutineCall
            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False, parseTree
            if "(" == self.tokenizer.symbol() or \
               "." == self.tokenizer.symbol():
                # now, it must be a subroutineCall structure
                self.tokenizer.rollBack()
                self.tokenizer.rollBack()

                if False == self.CompileSubroutineCall(parent):
                    print "Failed to match the 'subroutineCall' in %s" % (sys._getframe().f_code.co_name, )
                    return False, parseTree
            elif "[" == self.tokenizer.symbol():
                self.tokenizer.rollBack()
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier(), )

                # look up this identifier in the symbol table
                varName = self.tokenizer.identifier()
                entry = self.st.FindSymbol(varName)

                if None == entry:
                    print "Error: identifier %s referenced but not defined." % (varName, )
                    return False, parseTree
                else:
                    print "identifier %s found in symbol table, running index %d" % (varName, entry.GetIndex())

                if None == self.tokenizer.advance():
                    print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                    return False, parseTree

                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.symbol(), )

                if False == self.CompileExpression(parent):
                    print "Failed to match the expression in %s" % (sys._getframe().f_code.co_name, )
                    return False, parseTree

                if None == self.tokenizer.advance():
                    print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                    return False, parseTree

                if "]" == self.tokenizer.symbol():
                    item = ET.SubElement(parent, self.tokenizer.tokenType())
                    item.text = " %s " % (self.tokenizer.symbol(), )
                else:
                    print "Failed to match the ']' in %s" % (sys._getframe().f_code.co_name, )
                    return False, parseTree
            else:
                self.tokenizer.rollBack()
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.identifier(), )

                # look up this identifier in the symbol table
                varName = self.tokenizer.identifier()
                entry = self.st.FindSymbol(varName)

                if None == entry:
                    print "Error: identifier %s referenced but not defined." % (varName, )
                    return False, parseTree
                else:
                    print "identifier %s found in symbol table, running index %d" % (varName, entry.GetIndex())

        elif "(" == self.tokenizer.symbol():  # an expression in parentheses
            parent = ET.SubElement(parent, "term")
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            retVal, subTree = self.CompileExpression(parent)
            if False == retVal:
                print "Failed to match the expression in %s" % (sys._getframe().f_code.co_name, )

            parseTree.AddNode(subTree.root)

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False, parseTree

            if ")" == self.tokenizer.symbol():
                item = ET.SubElement(parent, self.tokenizer.tokenType())
                item.text = " %s " % (self.tokenizer.symbol(), )
            else:
                print "Failed to match the ) in %s" % (sys._getframe().f_code.co_name, )
                return False, parseTree

        elif "-" == self.tokenizer.symbol() or "~" == self.tokenizer.symbol():  # an expression prefixed by unary operators
            parent = ET.SubElement(parent, "term")

            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )
            if False == self.CompileTerm(parent):
                print "Failed to match 'term' in %s" % (sys._getframe().f_code.co_name, )
                return False, parseTree
        else:
            self.tokenizer.rollBack()
            return False, parseTree

        return True, parseTree

    def CompileExpressionList(self, parent):
        '''
        Compile a (possibly empty) comma-separated list of expressions
        '''
        self.argNum = 0

        parent = ET.SubElement(parent, "expressionList")
        ET.SubElement(parent, "pad")
        retVal, parseTree = self.CompileExpression(parent)
        if False == retVal:
            return False
 
        parseTree.PostOrderTraversal(parseTree.root)
        for item in parseTree.RPN:
            if item in "+-*/":
                self.vw.WriteArithMetic(item)
            else:
                self.vw.WritePush(item)

        self.argNum += 1
 
        if None == self.tokenizer.advance():
            print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
            return False

        # (, expression)*
        while "," == self.tokenizer.symbol():
            item = ET.SubElement(parent, self.tokenizer.tokenType())
            item.text = " %s " % (self.tokenizer.symbol(), )

            retVal, parseTree = self.CompileExpression(parent)
            if False == retVal:
                print "Failed to match the 'expression' in %s" % (sys._getframe().f_code.co_name, )
                return False
            parseTree.PostOrderTraversal(parseTree.root)
            for item in parseTree.RPN:
                if item in "+-*/":
                    self.vw.WriteArithMetic(item)
                else:
                    self.vw.WritePush(item)
            self.argNum += 1

            if None == self.tokenizer.advance():
                print "Run out of tokens in %s" % (sys._getframe().f_code.co_name, )
                return False

        self.tokenizer.rollBack()
        return True


class JackTokenizer:
    '''
    Remove all comments and white space from the input stream and breaks it
    into Jack lanaguage tokens, as specified by the Jack grammar
    '''
    def __init__(self, file_path):
        self.in_file_path = file_path
        self.fd_in_file = None
        # read the file and sanitize the content
        try:
            self.fd_in_file = open(file_path, "r")
        except IOError as e:
            print "I/O error: %s" % (str(e), )
            sys.exit(1)
        except Exception as e:
            print "Unexpected error: %s" % (str(e), )
            sys.exit(1)
        self.file_content = self.fd_in_file.read()
        self.file_content_list = self.input_sanitize(self.file_content)
        self.tok_list = []

        # the first step in the syntax analysis of a program is to group the characters into tokens
        self.tokenize()

        # prepare for the next steps
        self.tok_len = len(self.tok_list)
        self.token_index = -1
        self.current_token = None # there is no current token initially

    def advance(self):
        '''
        API function
        Gets the next token from the input and makes it the current token.
        This method should only be called if hasMoreTokens() is True. Initialy,
        there is no current token
        '''
        if True == self.hasMoreTokens():
            self.token_index += 1
            self.current_token = self.tok_list[self.token_index]
            return self.current_token
        else:
            return None

    def rollBack(self):
        if self.token_index > 0:
            self.token_index -= 1
            self.current_token = self.tok_list[self.token_index]
            return self.current_token
        else:
            return None

    def hasMoreTokens(self):
        '''
        API function
        Do we have more tokens in the input
        '''
        if self.token_index < (self.tok_len - 1):
            return True
        else:
            return False

    def tokenType(self):
        '''
        API function
        Returns the type of the current token
        '''
        return self.current_token.get_type()

    def keyWord(self):
        '''
        API function
        Returns the keyword which is the current token. Should be called only
        when tokenType() is KEYWORD
        '''
        if "keyword" == self.tokenType():
            return self.current_token.get_mth_str()
        else:
            return None

    def symbol(self):
        '''
        API function
        Returns the character which is the current token. Should be called only
        when tokenType() is SYMBOL
        '''
        if "symbol" == self.tokenType():
            return self.current_token.get_mth_str()
        else:
            return None

    def identifier(self):
        '''
        API function
        Returns the identifier which is the current token. Should be called only
        when tokenType() is IDENTIFIER
        '''
        if "identifier" == self.tokenType():
            return self.current_token.get_mth_str()
        else:
            return None

    def intVal(self):
       '''
        API function
        Returns the integer values of the current token. Should be called only
        when tokenType() is INT_CONST
       '''
       if "integerConstant" == self.tokenType():
           return int(self.current_token.get_mth_str())
       else:
           return None

    def stringVal(self):
       '''
        API function
        Returns the integer values of the current token. Should be called only
        when tokenType() is INT_CONST
       '''
       if "stringConstant" == self.tokenType():
           return self.current_token.get_mth_str()
       else:
           return None

    def input_sanitize(self, input_content):
        '''
        remove all the comments
        '''
        # get rid of the leading and trailing whitespaces
        temp = input_content.strip()
        # remove multi-lines comments. Note that the question mark(?) here indicates a non-greedy match mode
        temp = re.sub("\/\*.*?\*\/", "", temp, flags = re.DOTALL)
        # remove single line comments
        temp = re.sub("\/\/.*", "", temp)
        sanitized_content = temp.strip()
        return [l.strip() for l in sanitized_content.split("\n") if "" != l.strip()]

    def process_single_line(self, line_str):
        '''
        tokenize one line of code
        '''
        obj_mth = None
        list_obj_tok = []
        try_time = 0
        while "" != line_str:
            try_time += 1
            obj_tok = None
            token_type = ""
            # try to match the first token against the line string from left to right
            for regex in lex_ele_regex_list:
                obj_mth = regex.match(line_str)
                if None != obj_mth:
                    obj_tok = Token(regex.get_name(), obj_mth.group(0), obj_mth.group(1))
                    list_obj_tok.append(obj_tok)
                    token_type = regex.get_name()
                    break

            if None == obj_tok:
                print "No regex matched this line: %s at %d try" % (line_str, try_time, )
                sys.exit(1)

            if "keyword" == token_type:
                # should not contain the tail of the pattern
                entire_match = obj_tok.get_mth_str()
            else:
                entire_match = obj_tok.get_raw_str()
            # remove the matched part from line string
            len_mth = len(entire_match)
            start  = line_str.find(entire_match)
            line_str = line_str[start + len_mth:].strip()

        return list_obj_tok

    def tokenize(self):
        for line in self.file_content_list:
            tok_list_single_line = self.process_single_line(line)
            self.tok_list += tok_list_single_line


class SymbolTable:
    '''
    The symbol table associates the identifier names found in the program with identifier properties
    needed for compilation: type, kind and running index. The symbol tables for Jack programs has two
    nested scopes(class/subroutine)
    '''
    class SymbolEntry:
        '''
        one entry in the symbol table
        '''
        def __init__(self, name, symbolType, kind, index):
            self.name = name
            self.type = symbolType
            self.kind = kind
            self.runningIndex = index

        def GetName(self):
            return self.name

        def GetType(self):
            return self.type

        def GetKind(self):
            return self.kind

        def GetIndex(self):
            return self.runningIndex


    def __init__(self):
        # class scope symbol table
        self.classTable = {
            "static": [],
            "field": []
        }
        # subroutine scope symbol table
        self.subroutineName = None
        self.subroutineTable = None

        self.subroutineTableStack = []
        self.classNameList = []
        self.subroutineNameList = []

    def GetSubroutineTable(self):
        '''
        Get the subroutine table in the current scope
        '''
        if 0 == len(self.subroutineTableStack):
            return None
        else:
            return self.subroutineTableStack.pop()

    def StartSubroutineScope(self, name):
        '''
        Start a new subroutine scope. i.e., resets the subrotine's symbol table
        '''
        self.subroutineName = name
        self.subroutineTable = {
            "argument": [],
            "var": []
        }

    def EndSubroutineScope(self):
        '''
        End the current subroutine scope
        '''
        subroutineTable = {
            "name": self.subroutineName,
            "table": self.subroutineTable
        }
        self.subroutineTableStack.append(subroutineTable)

        self.subroutineName = None
        self.subroutineTable = None

    def FindSymbol(self, name):
        '''
        find the symbol entry with given name
        '''
        entry = self.FindSymbolSubroutine(name)
        if None != entry:
            return entry
        entry = self.FindSymbolClass(name)
        if None != entry:
            return entry
        return None

    def FindSymbolClass(self, name):
        '''
        find the symbol entry with given name in class scope
        '''
        for key, valList in self.classTable.iteritems():
            for item in valList:
                if name == item.GetName():
                    return item
        return None

    def FindSymbolSubroutine(self, name):
        '''
        find the symbol entry with given name in subroutine scope
        '''
        if None == self.subroutineTable:
            return None
        for key, valList in self.subroutineTable.iteritems():
            for item in valList:
                if name == item.GetName():
                    return item
        return None

    def GetEntriesOfKinds(self, kind):
        if "static" == kind or "field" == kind:
            return self.classTable[kind]
        elif "argument" == kind or "var" == kind:
            if None == self.subroutineTable:
                print "Error: no symbol of kind %s in the current scope" % (kind, )
                return None
            return self.subroutineTable[kind]

    def AddToTables(self, entry):
        kind = entry.GetKind()
        if "static" == kind or "field" == kind:
            self.classTable[kind].append(entry)
        elif "argument" == kind or "var" == kind:
            if None == self.subroutineTable:
                print "Error: no symbol of kind %s in the current scope" % (kind, )
                return None
            self.subroutineTable[kind].append(entry)

    def Define(self, symbolName, symbolType, symbolKind):
        '''
        Define a new identifier with given attributes
        '''
        currentEntriesNumber = len(self.GetEntriesOfKinds(symbolKind))
        se = self.SymbolEntry(symbolName, symbolType, symbolKind, currentEntriesNumber)  # the number of the current entries could be used as index value
        self.AddToTables(se)

    def GetVarCount(self, kind):
        '''
        Return the number of variables of the given kind already defined in the current scope
        '''
        if "static" == kind or "field" == kind:
            return len(self.classTable[kind])
        elif "argument" == kind or "var" == kind:
            if None == self.subroutineTable:
                print "Error: no symbol of kind %s in the current scope" % (kind, )
                return None
            return len(self.subroutineTable[kind])

    def KindOf(self, name):
        '''
        Return the kind of the named identifier in the current scope,
        If the identifier is unknown in the current scope, return None
        '''
        for key, valList in self.classTable.iteritems():
            for item in valList:
                if item.GetName() == name:
                    return key
        if None == self.subroutineTable:
            print "Error: no symbol of kind %s in the current scope" % (kind, )
            return None
        for key, valList in self.subroutineTable.iteritems():
            for item in valList:
                if item.GetName() == name:
                    return key

        return None

    def TypeOf(self, name):
        '''
        Return the type of the named identifier in the current scope,
        '''
        for key, valList in self.classTable.iteritems():
            for item in valList:
                if item.GetName() == name:
                    return item.GetType()
        if None == self.subroutineTable:
            print "Error: no symbol of kind %s in the current scope" % (kind, )
            return None
        for key, valList in self.subroutineTable.iteritems():
            for item in valList:
                if item.GetName() == name:
                    return item.GetType()

        return None

    def IndexOf(self, name):
        '''
        Return the index assigned to the named identifier
        '''
        for key, valList in self.classTable.iteritems():
            for item in valList:
                if item.GetName() == name:
                    return item.GetIndex()
        if None == self.subroutineTable:
            print "Error: no symbol of kind %s in the current scope" % (kind, )
            return None
        for key, valList in self.subroutineTable.iteritems():
            for item in valList:
                if item.GetName() == name:
                    return item.GetIndex()

        return None

    def DisplayContent(self):
        '''
        Display the content of this symbol table,
        and it is used for test purpose
        '''
        print "class scope symbol table:"
        print "%12s | %12s | %12s | %12s" % ("Name", "Type", "Kind", "runningIndex")
        for key, valList in self.classTable.iteritems():
            for item in valList:
                print "%12s | %12s | %12s | %12s" % (item.GetName(), item.GetType(), item.GetKind(), item.GetIndex())

        for entry in self.subroutineTableStack:
            print "subroutine scope symbol table for %s:" % (entry["name"], )
            print "%12s | %12s | %12s | %12s" % ("Name", "Type", "Kind", "runningIndex")
            for key, valList in entry["table"].iteritems():
                for item in valList:
                    print "%12s | %12s | %12s | %12s" % (item.GetName(), item.GetType(), item.GetKind(), item.GetIndex())

class VMWriter:
    '''
    Emits VM commands into a file, using the VM command syntax
    '''
    def __init__(self, inPath):
        # process the output file path
        if os.path.isfile(inPath):
            self.targetPath = inPath.split(".")[0] + ".vm"
        else:
            print "Error: cannot create output file for %s" % (file_path, )
        # vm commands list
        self.vmCmdList = []

    def CreateOutputFile(self):
        try:
            fdOutputFile = open(self.targetPath, "w")
        except IOError as e:
            print "I/O error: %s" % (str(e), )
            sys.exit(1)
        except Exception as e:
            print "Unexpected error: %s" % (str(e), )
            sys.exit(1)
        finally:
            for line in self.vmCmdList:
                fdOutputFile.write(line + "\n")
            fdOutputFile.close()
            print "%s generated " % (self.targetPath, )

    def WriteReturn(self, void = False):
        if True == void:
            self.vmCmdList.append("push constant 0")
        self.vmCmdList.append("return")

    def WriteCall(self, name, num):
        self.vmCmdList.append("call %s %d" % (name, num, ))

    def WriteFunction(self, name, varNum):
        self.vmCmdList.append("function %s %d" % (name, varNum))

    def WriteArithMetic(self, op):
        if "+" == op:
            self.vmCmdList.append("add")
        elif "-" == op:
            self.vmCmdList.append("sub")
        elif "*" == op:
            self.vmCmdList.append("call Math.multiply 2")
        elif "/" == op:
            self.vmCmdList.append("call Math.divide 2")

    def WritePush(self, val):
        self.vmCmdList.append("push constant %d" % (int(val)))


class JackCompiler:
    '''
    top level module that sets up and invokes other sub-modules
    '''
    def __init__(self, path):
        self.list_input_files = self.path_pre_process(path)
        self.list_jt = []
        self.list_ce = []

        if 0 == len(self.list_input_files):
            print "Error: no input files"
            sys.exit(1)

        # create tokenizers
        for f in self.list_input_files:
            print "Input file %s found" % (f, )
            jt = JackTokenizer(f)
            self.list_jt.append(jt)

        # create compilation engines
        for jt in self.list_jt:
            # avoid emptyfiles
            if jt.tok_len > 0:
                ce = CompilationEngine(jt)
                self.list_ce.append(ce)

    def compile(self):
        # call the compile command on all CompilationEngine instances
        for ce in self.list_ce:
            ce.StartCompiling()

    def validate_file_path(self, file_path):
        if False == file_path.lower().endswith(".jack"):
            return False
        return True

    def path_pre_process(self, target_path):
        '''
        if the system argument is a path to file, then translate this file to a single xml file
        if the system argument is a foler, then translate all the jack files in that folder to xml files
        '''
        list_files = []
        # Check if the input path is valid
        if False == os.path.exists(target_path):
            print "Input path %s does not exist" % (target_path, )
            return list_files

        if True == os.path.isfile(target_path):
            if True == self.validate_file_path(target_path):
                list_files.append(target_path)
        elif True == os.path.isdir(target_path):
            files = os.listdir(target_path)
            for f in files:
                file_path = target_path + "/" + f
                if True == self.validate_file_path(file_path):
                    list_files.append(file_path)
        else:
            print "Input path is neither a file nor a folder!"

        return list_files


def main():
    # arguments pre-processing
    if len(sys.argv) <= 1:
        print "Please supply the path to the .jack file(s)"
        sys.exit(1)

    INPUT_PATH = os.path.normpath(sys.argv[1])

    jc = JackCompiler(INPUT_PATH)
    jc.compile()

if "__main__" == __name__:
    main()
